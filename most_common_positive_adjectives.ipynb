{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "most_common_positive_adjectives.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtX2ryvS0sFdaoIY2QhCyW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katkasian/mysql-csv/blob/master/most_common_positive_adjectives.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ34hzJshApJ",
        "colab_type": "text"
      },
      "source": [
        "**COMING UP WITH A SHORT LIST OF POSITIVE ADJECTIVES** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-xCWBLDhPgB",
        "colab_type": "text"
      },
      "source": [
        "This is a preparatory stage of my SQLite analysis of the Yelp dataset. I wanted to perform a sentiment analysis of reviews users have written to see if users who write more positive reviews have more followers. As sqlite does not support list-like datatypes, I needed a short list of common and strongly positive words (in this case, adjectives only). The below code uses Python libraries (pandas, nltk) and a SentiWordNet dataset to find most common strongly positive words. Commonality is operationaly defined as frequency of usage in reviews found in Brown corpus. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh32SfQLb2SA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3a742731-241d-4aec-e97d-44a0eb3b1111"
      },
      "source": [
        "#importing necessary libraries, downloading brown corpus to use in google colab\n",
        "import pandas as pd\n",
        "from nltk import FreqDist\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "from  nltk.corpus import brown"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XxnBAF4Jt-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "99457f5e-cde0-401c-db8a-5bb12b5ea4bc"
      },
      "source": [
        "#reading SentiWordNet dataset as Pandas dataframe\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/TharinduMunasinge/Twitter-Sentiment-Analysis/master/sentiwordnet.csv\", sep = \"\\t\")\n",
        "cols =  [\"POS\", \"pos_score\", \"neg_score\", \"term\"]\n",
        "df.columns = cols\n",
        "df.head()"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>POS</th>\n",
              "      <th>pos_score</th>\n",
              "      <th>neg_score</th>\n",
              "      <th>term</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>unable#1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>dorsal#2 abaxial#1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>ventral#2 adaxial#1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>acroscopic#1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>basiscopic#1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  POS  pos_score  neg_score                 term\n",
              "0   a        0.0       0.75             unable#1\n",
              "1   a        0.0       0.00   dorsal#2 abaxial#1\n",
              "2   a        0.0       0.00  ventral#2 adaxial#1\n",
              "3   a        0.0       0.00         acroscopic#1\n",
              "4   a        0.0       0.00         basiscopic#1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUN1NHBcQq3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating two dataframes with strongly negative and strongly positive adjectives\n",
        "def adj(col):\n",
        "  \"\"\"A function that returns a dataframe with highest scoring negative or positive adjectives. Enter the score column\"\"\"\n",
        "  high_words = df.term[(col >= 0.8) & (df.POS == \"a\")]\n",
        "  high_score =  col[(col >= 0.8) & (df.POS == \"a\")]\n",
        "  high_df = pd.DataFrame({\"word\":high_words, \"score\":high_score})\n",
        "  high_df[\"word\"] = high_df.word.str.replace(\"#.+\", \"\")\n",
        "  return high_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHZYi7J4RbJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "3c6c636e-ef93-4ec9-8800-05604d2c664c"
      },
      "source": [
        "pos_df = adj(df.pos_score)\n",
        "pos_df"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>veracious</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>selfless</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>632</th>\n",
              "      <td>perked_up</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>attractive</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>piquant</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12984</th>\n",
              "      <td>topping</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13245</th>\n",
              "      <td>esthetic</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13936</th>\n",
              "      <td>virtuous</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14192</th>\n",
              "      <td>salubrious</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14344</th>\n",
              "      <td>worthy</td>\n",
              "      <td>0.875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>85 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             word  score\n",
              "108     veracious  0.875\n",
              "535      selfless  0.875\n",
              "632     perked_up  0.875\n",
              "898    attractive  0.875\n",
              "903       piquant  0.875\n",
              "...           ...    ...\n",
              "12984     topping  1.000\n",
              "13245    esthetic  0.875\n",
              "13936    virtuous  0.875\n",
              "14192  salubrious  0.875\n",
              "14344      worthy  0.875\n",
              "\n",
              "[85 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6IlVxmxbpIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deteriming most common adjectives with Brown corpus\n",
        "def common_adjs():\n",
        "  brown.tagged_words(categories = 'reviews')\n",
        "  adj = [word.lower() for word, pos in brown.tagged_words(categories = 'reviews') if pos == 'JJ']\n",
        "  fdist = FreqDist(adj)\n",
        "  common = [word for word in fdist.keys() if fdist[word] > 5]\n",
        "  return common"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcIyNTgjVbic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "commonads = common_adjs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-NOEwigaMwb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#determining strongly positive common adjectives\n",
        "strong_pos = set(list(pos_df[pos_df.word.isin(commonads)].word))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqR3HomvfL7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25fbe1fb-65ad-46a6-de4a-282d43b0804c"
      },
      "source": [
        "strong_pos"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attractive', 'charming', 'good', 'intellectual', 'nice', 'solid', 'superb'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVUiHq1gkDH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}